{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Nepali Sentiment Analysis with BERT \n\nThis notebook demonstrates how to fine-tune a BERT-based model for sentiment analysis on Nepali text using a publicly available dataset and GPU resources on Kaggle.  \nThe final goal is to export the trained model and later use it in a FastAPI backend, a Streamlit UI, and a Dockerized deployment.  \n\n---\n\n## 1. Project overview\n\nThe main objective of this project is to build a **Nepali sentiment classifier** that can automatically label input sentences as positive, negative, or neutral.  \nWe focus on modern Transformer models and specifically on a BERT variant that is trained for the Nepali language, so that the model can handle Devanagari script and Nepali vocabulary.  \n\nIn this notebook we will:  \n- Load the `Shushant/NepaliSentiment` dataset from Hugging Face.  \n- Fine-tune the `Shushant/nepaliBERT` model for sentiment classification.  \n- Use Kaggle’s GPU accelerator to speed up training.  \n- Evaluate the model on a held-out test set and save the fine-tuned weights for later deployment.  \n\n---\n\n## 2. Dataset description: `Shushant/NepaliSentiment`\n\nFor this project we use the **NepaliSentiment** dataset hosted on Hugging Face under the name `Shushant/NepaliSentiment`.  \nThe dataset contains Nepali text samples with sentiment labels, which are suitable for training and evaluating a three-class sentiment classifier.  \n\nIn this dataset, the labels are defined as follows:  \n- `0` → negative sentiment  \n- `1` → positive sentiment  \n- `2` → neutral sentiment  \n\nIn the later code cells we will:  \n- Load the dataset directly from Hugging Face using the `datasets` library.  \n- Inspect a few examples to understand the text format and label distribution.  \n- Split the data into training and test sets if they are not already provided.  \n\n---\n\n## 3. Model choice: `Shushant/nepaliBERT`\n\nWe use **Shushant/nepaliBERT**, a BERT-base model pre-trained specifically on Nepali news text, containing about 10 million Nepali sentences (≈4.6 GB of data).  \nBecause this model is trained only on Nepali text, it captures Nepali grammar, vocabulary, and script better than generic multilingual models, which makes it a strong choice for Nepali sentiment analysis.  \n\nIn this notebook, we will:  \n- Load `Shushant/nepaliBERT` using the Hugging Face `transformers` library.  \n- Attach a classification head to predict sentiment labels (e.g., negative, neutral, positive).  \n- Fine-tune all parameters on the `Shushant/NepaliSentiment` dataset using GPU acceleration.  \n\n---\n\n## 4. Running on Kaggle with GPU\n\nThis notebook is designed to run on Kaggle with a GPU accelerator to speed up BERT fine-tuning.  \nBefore executing the training cells, please ensure that the notebook accelerator is set to GPU in the **Settings → Accelerator** panel.  \n\nIn the setup section we will:  \n- Check that a GPU is available using PyTorch (`torch.cuda.is_available()`).  \n- Move the model and input tensors to the GPU device for faster training and inference.  \n- Configure batch sizes and number of epochs to fit within Kaggle’s GPU memory and runtime limits.  \n\n---\n\n## 5. Training and evaluation plan\n\nOur training pipeline will follow standard steps used for BERT-based text classification.  \nWe will use a PyTorch training loop to fine-tune the model on the training split and evaluate on the test split.  \n\nKey steps:  \n- Tokenize the Nepali text using the nepaliBERT tokenizer with appropriate `max_length`, padding, and truncation.  \n- Train for a small number of epochs (for example, 5) with a low learning rate suitable for BERT (e.g., 2e-5).  \n- Monitor metrics such as accuracy and F1-score on the validation or test set to avoid overfitting.  \n\nAt the end of training, we will report the final metrics and show example predictions on a few Nepali sentences to illustrate how the model behaves.  \n\n---\n\n## 6. Saving the model for deployment\n\nOnce the model is trained, we need to export it so that it can be integrated into a FastAPI service and a Streamlit UI later.  \nKaggle stores files written to `/kaggle/working` as notebook outputs, which we can download after the run and use in other environments.  \n\nIn the final section of this notebook we will:  \n- Save the fine-tuned model and tokenizer into a directory under `/kaggle/working/nepali-sentiment-model`.  \n- Optionally compress that directory into a ZIP file for easier download from the “Output” tab.  \n- Briefly describe how this exported model will later be loaded in a FastAPI app and called by a Streamlit frontend.  \n\n---\n\n## 7. Notebook structure\n\nFor clarity, the rest of the notebook is organized as follows.  \n\n1. **Imports and environment setup**  \n2. **Loading the NepaliSentiment dataset**  \n3. **Exploratory data analysis (EDA)**  \n4. **Tokenization and data preparation**  \n5. **Model definition and training configuration**  \n6. **Fine-tuning nepaliBERT on GPU**  \n7. **Evaluation and example predictions**  \n8. **Saving and exporting the model**  \n\nThis structure follows common best practices for well-documented Kaggle notebooks and should make it easy for readers to understand and reproduce the full workflow.","metadata":{"_uuid":"248c1870-01d6-4445-86a5-64f0e09c0538","_cell_guid":"c44f11af-7fa4-4170-8ed5-9ef96adc066b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"# Code Starts From Here","metadata":{"_uuid":"f9d55395-ab9b-4066-a9c6-4921a645ae21","_cell_guid":"8c63a56f-3228-4270-b790-0a10620fa00c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 1. Install libraries and import modules","metadata":{"_uuid":"b3bbd049-1465-46fb-b25d-ec061fc13175","_cell_guid":"cdf7dc77-92dc-4de3-bb7c-e5d6ce3d84db","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"!pip install -q \"protobuf==3.20.3\"\n\nimport os\nos.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n\nprint(\"Pinned protobuf to 3.20.3 and set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python.\")","metadata":{"_uuid":"6652bffb-5bbc-456c-a89c-28277d472c47","_cell_guid":"43f53b43-db34-43fd-a773-0ab310b3586b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-20T09:15:06.942849Z","iopub.execute_input":"2025-11-20T09:15:06.943362Z","iopub.status.idle":"2025-11-20T09:15:10.119195Z","shell.execute_reply.started":"2025-11-20T09:15:06.943334Z","shell.execute_reply":"2025-11-20T09:15:10.118090Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Pinned protobuf to 3.20.3 and set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -q transformers datasets accelerate\n\nimport os\nimport random\nimport numpy as np\nimport torch\n\nfrom torch.utils.data import DataLoader\nfrom torch.optim import AdamW\n\nfrom datasets import load_dataset, concatenate_datasets\nfrom transformers import (\n    BertTokenizerFast,\n    BertForSequenceClassification,\n    get_linear_schedule_with_warmup,\n)\n\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report","metadata":{"_uuid":"6ac74be3-1617-4a23-b42f-014a625da97a","_cell_guid":"19470fba-274f-41ce-ab9b-c6f7a76f2f56","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-20T09:15:10.120601Z","iopub.execute_input":"2025-11-20T09:15:10.120846Z","iopub.status.idle":"2025-11-20T09:15:24.450359Z","shell.execute_reply.started":"2025-11-20T09:15:10.120819Z","shell.execute_reply":"2025-11-20T09:15:24.449763Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"2025-11-20 09:15:19.774632: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763630119.796914     384 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763630119.803723     384 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## 2. Set random seeds and configure device","metadata":{"_uuid":"518bf6ec-1cb7-4e15-b912-37d408c2176b","_cell_guid":"977c8236-be23-49b8-af6a-1b2f6ed704c0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# For reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\n# Use GPU if available (Kaggle usually provides a GPU when enabled)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"_uuid":"efaed76d-df28-4b9a-8b01-873248846654","_cell_guid":"832369ef-516d-4e73-89fb-cbd622a75d02","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-20T09:15:24.451136Z","iopub.execute_input":"2025-11-20T09:15:24.451709Z","iopub.status.idle":"2025-11-20T09:15:24.458215Z","shell.execute_reply.started":"2025-11-20T09:15:24.451682Z","shell.execute_reply":"2025-11-20T09:15:24.457655Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## 3. Load the NepaliSentiment dataset","metadata":{"_uuid":"c85a8d9e-3453-43ed-91c8-6f87357f85d9","_cell_guid":"8bb437a2-82d8-462b-9e95-de1202995a0d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"raw_dataset = load_dataset(\"Shushant/NepaliSentiment\")\n\n# Merge original train and test into a single dataset\nfull_dataset = concatenate_datasets(\n    [raw_dataset[\"train\"], raw_dataset[\"test\"]]\n)\n\n# Re‑split merged data into 90% train, 10% test\ndataset = full_dataset.train_test_split(test_size=0.1, seed=42)\ndataset","metadata":{"_uuid":"c8477186-6785-47bd-ae5e-bbaf1dc1f7be","_cell_guid":"062d0ba3-9d0c-472b-81f4-295d6a882a3b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-20T09:15:24.459894Z","iopub.execute_input":"2025-11-20T09:15:24.460111Z","iopub.status.idle":"2025-11-20T09:15:26.115877Z","shell.execute_reply.started":"2025-11-20T09:15:24.460094Z","shell.execute_reply":"2025-11-20T09:15:26.115304Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 7196\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 800\n    })\n})"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"## 4. Inspect a few samples and label meaning","metadata":{"_uuid":"c86aa275-8952-4b1b-9996-74098baa8d13","_cell_guid":"dbfb69ad-b61e-4f88-a8dc-c72beca7dfbe","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"print(dataset[\"train\"].features)\n\nfor i in range(5):\n    example = dataset[\"train\"][i]\n    print(f\"\\nExample {i}:\")\n    print(\"Text:\", example[\"text\"])\n    print(\"Label:\", example[\"label\"])","metadata":{"_uuid":"02ca5993-8f36-411c-b341-2f3248a84e27","_cell_guid":"1a6580ac-2c87-422c-bf65-27b3a796724a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-20T09:15:26.116536Z","iopub.execute_input":"2025-11-20T09:15:26.116750Z","iopub.status.idle":"2025-11-20T09:15:26.122633Z","shell.execute_reply.started":"2025-11-20T09:15:26.116732Z","shell.execute_reply":"2025-11-20T09:15:26.121935Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"{'text': Value('string'), 'label': Value('string')}\n\nExample 0:\nText: अभिन्ता राउतको स्थिति सुन्दा आँसु नै थामिएन ! तथापि ती कुलङ्गार  \"घृणित\"को निन्दा गरेपछि अधुरै रहन्छ, नेता भएपछि जे जस्तोसुकै अपराध गरेपनि हुने, अनागरिक नागरिक र नागरिकलाई अनागरिक, कालोलाई सेतो सेतोलाई कालो ? यो कस्तो देश र कस्तो कानुन कहिले सम्म एस्तै ???\nLabel: 0\n\nExample 1:\nText: देश यस्तो हालत पुग्दा पनि जनता आखिर किन चुप छन नेपाली जनता नबोल्नुको कारण केहोला यसरि जनता चुप लाग्ने हो भने नेताहरु त झन मातिन लागे त गाठे\nLabel: 0\n\nExample 2:\nText: दोसि लाई कडा भन्दा कडा कारबाही गर्न माग गर्दछु\nLabel: 0\n\nExample 3:\nText: यो मुजि 70 करोड लाई किन ल्याउनु हो मुजि धमला\nLabel: 0\n\nExample 4:\nText: एमसिसिबारे प्रचन्ड ज्युको धाराणा सहि छ तर सझदारिमा हैन ‘परिमार्जन भएमा पास’ भन्नु ठिक । तपाईको ब्याक्तित्व केपि ओलीसंग एक पर्तिसत पनि मिल्दैन, कहिले पनि सहकार्य नगर्नु राम्रो होला।  आफ्नो सुरक्षाको ख्याल राख्दै पत्रकारले लेटदैमा असुरंक्षित जिवनशैली नअपनाउनुनै राम्रो होला l जालझेल काम नलागे भौतिक आक्रमण गरेर सिध्याउने दाउ धेरैको छ भन्ने बुज्न गारो छैन ।\nLabel: 2\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"id2label = {\n    0: \"negative\",\n    1: \"positive\",\n    2: \"neutral\",\n}\nlabel2id = {v: k for k, v in id2label.items()}\n\nprint(id2label)","metadata":{"_uuid":"1ef2809c-8d4a-4844-90cc-916004b29cbf","_cell_guid":"cb8454b4-d0d6-463d-bd7c-ad389414169b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-20T09:15:26.123226Z","iopub.execute_input":"2025-11-20T09:15:26.123447Z","iopub.status.idle":"2025-11-20T09:15:26.134946Z","shell.execute_reply.started":"2025-11-20T09:15:26.123431Z","shell.execute_reply":"2025-11-20T09:15:26.134258Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"{0: 'negative', 1: 'positive', 2: 'neutral'}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## 5. Load the nepaliBERT tokenizer and model","metadata":{"_uuid":"2a07f6b8-9fa8-4e23-9b0d-87041a0aeb0b","_cell_guid":"e690f248-c999-4af2-ba1a-2377f9d3592a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"MODEL_NAME = \"Shushant/nepaliBERT\"\n\n# Load tokenizer and model\ntokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n\nmodel = BertForSequenceClassification.from_pretrained(\n    MODEL_NAME,\n    num_labels=len(id2label),\n    id2label=id2label,\n    label2id=label2id,\n)\n\nmodel.to(device)\nprint(\"Model loaded and moved to:\", device)","metadata":{"_uuid":"e9debe8b-2f81-4431-8cb3-dd8f3d968362","_cell_guid":"12df72d9-96d3-41fd-a239-7b46eedeceb3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-20T09:15:26.135622Z","iopub.execute_input":"2025-11-20T09:15:26.135817Z","iopub.status.idle":"2025-11-20T09:15:27.352306Z","shell.execute_reply.started":"2025-11-20T09:15:26.135802Z","shell.execute_reply":"2025-11-20T09:15:27.351700Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at Shushant/nepaliBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model loaded and moved to: cuda\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## 6. Tokenize the dataset","metadata":{"_uuid":"79a36b7b-90e6-4fcc-9289-a4b2a2633431","_cell_guid":"077566e9-b340-42d6-8de3-00d834790eb5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"### 1. Max character length in train[\"text\"]","metadata":{"_uuid":"d2ab61ef-4e52-41c3-b389-355bcad0706e","_cell_guid":"e9cbd487-225b-45ae-a9ab-8bec77dce1be","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Compute character lengths of each text in the train split\ndef add_char_len(example):\n    txt = example[\"text\"]\n    # Handle possible None values safely\n    txt = \"\" if txt is None else str(txt)\n    return {\"char_len\": len(txt)}\n\ntrain_with_len = dataset[\"train\"].map(add_char_len)\n\nmax_char_len = max(train_with_len[\"char_len\"])\navg_char_len = sum(train_with_len[\"char_len\"]) / len(train_with_len[\"char_len\"])\n\nprint(\"Max char length in train:\", max_char_len)\nprint(\"Average char length in train:\", avg_char_len)","metadata":{"_uuid":"231a1eb2-4012-4ce6-9e13-4eca2464375f","_cell_guid":"f005a1e7-83e9-49d4-bc16-3e4e8d38e9ea","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-20T09:15:27.353009Z","iopub.execute_input":"2025-11-20T09:15:27.353219Z","iopub.status.idle":"2025-11-20T09:15:27.552703Z","shell.execute_reply.started":"2025-11-20T09:15:27.353189Z","shell.execute_reply":"2025-11-20T09:15:27.552108Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Max char length in train: 2855\nAverage char length in train: 88.4339911061701\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### 2. Max token length with the nepaliBERT tokenizer","metadata":{"_uuid":"9dccd017-1a70-4136-8ee0-71deca4d45ef","_cell_guid":"594fea0b-9be7-4c1a-a022-697efa19112c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def add_token_len(example):\n    txt = example[\"text\"]\n    txt = \"\" if txt is None else str(txt)\n    tokens = tokenizer(\n        txt,\n        truncation=False,          # do not truncate, we want the true length\n        add_special_tokens=True,   # includes [CLS] and [SEP]\n    )\n    return {\"token_len\": len(tokens[\"input_ids\"])}\n\ntrain_with_token_len = dataset[\"train\"].map(add_token_len)\n\nmax_token_len = max(train_with_token_len[\"token_len\"])\navg_token_len = sum(train_with_token_len[\"token_len\"]) / len(train_with_token_len[\"token_len\"])\n\nprint(\"Max token length in train:\", max_token_len)\nprint(\"Average token length in train:\", avg_token_len)","metadata":{"_uuid":"cdbe34c5-b1bb-4397-8833-0c48e666732f","_cell_guid":"a4e12f49-b97a-4c69-9b35-0f8b75d19743","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-20T09:15:27.553370Z","iopub.execute_input":"2025-11-20T09:15:27.553629Z","iopub.status.idle":"2025-11-20T09:15:27.764883Z","shell.execute_reply.started":"2025-11-20T09:15:27.553603Z","shell.execute_reply":"2025-11-20T09:15:27.764166Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Max token length in train: 954\nAverage token length in train: 29.785992217898833\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"MAX_LENGTH = 228\n\ndef preprocess_function(batch):\n    texts = [\n        t if (t is not None and str(t).strip() != \"\")\n        else \"\"\n        for t in batch[\"text\"]\n    ]\n    return tokenizer(\n        texts,\n        padding=\"max_length\",\n        truncation=True,\n        max_length=MAX_LENGTH,\n    )\n\n# Apply tokenizer to the whole dataset\nencoded_dataset = dataset.map(preprocess_function, batched=True)\n\n# Rename 'label' to 'labels' for the model\nencoded_dataset = encoded_dataset.rename_column(\"label\", \"labels\")\n\n# Convert labels to integer IDs (0, 1, 2) safely\ndef fix_labels(batch):\n    cleaned_labels = []\n    for lbl in batch[\"labels\"]:\n        s = str(lbl).strip()\n        if s in [\"0\", \"1\", \"2\"]:\n            cleaned_labels.append(int(s))\n        else:\n            # For any unexpected label like \"-\" or \"\", treat as neutral (2)\n            cleaned_labels.append(2)\n    batch[\"labels\"] = cleaned_labels\n    return batch\n\nencoded_dataset = encoded_dataset.map(fix_labels, batched=True)\n\nprint(\"Unique labels in train:\", set(encoded_dataset[\"train\"][\"labels\"]))\nprint(\"Type of one label:\", type(encoded_dataset[\"train\"][\"labels\"][0]))","metadata":{"_uuid":"a5ef7ca0-e6a2-432a-b89d-a4534f0ce6e1","_cell_guid":"61bad7f8-c7f1-4702-86f4-d620783035ba","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-20T09:15:27.767103Z","iopub.execute_input":"2025-11-20T09:15:27.767332Z","iopub.status.idle":"2025-11-20T09:15:28.070179Z","shell.execute_reply.started":"2025-11-20T09:15:27.767318Z","shell.execute_reply":"2025-11-20T09:15:28.069598Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8edcee8b3ef94cd788cd544280556b41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97d8600681904db0bb902fe1ecbcd428"}},"metadata":{}},{"name":"stdout","text":"Unique labels in train: {0, 1, 2}\nType of one label: <class 'int'>\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## 7. Create PyTorch DataLoaders","metadata":{"_uuid":"db5cbfb6-6dda-4250-be96-691bbdeb4bbd","_cell_guid":"fb619879-a462-4c5c-be1c-32ca4d2fadea","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nencoded_dataset.set_format(\n    type=\"torch\",\n    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n)\n\nBATCH_SIZE = 16\n\ntrain_dataset = encoded_dataset[\"train\"]\ntest_dataset = encoded_dataset[\"test\"]\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n# Quick sanity check\nbatch = next(iter(train_loader))\nfor k, v in batch.items():\n    print(k, type(v))","metadata":{"_uuid":"f6e4374d-8f08-4ab8-a4e4-ade8f9f7ca3c","_cell_guid":"e997d305-81c2-4290-a65f-329bea0c7952","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-20T09:15:28.070926Z","iopub.execute_input":"2025-11-20T09:15:28.071172Z","iopub.status.idle":"2025-11-20T09:15:28.080025Z","shell.execute_reply.started":"2025-11-20T09:15:28.071155Z","shell.execute_reply":"2025-11-20T09:15:28.079477Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"labels <class 'torch.Tensor'>\ninput_ids <class 'torch.Tensor'>\nattention_mask <class 'torch.Tensor'>\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"DataLoaders batch the tokenized dataset and optionally shuffle it so each epoch sees examples in a different order, which usually improves training.","metadata":{"_uuid":"b0c177c3-907e-4706-9171-814fbdfcf466","_cell_guid":"1648954d-04ec-425c-bb64-51e140f7f495","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 8. Define optimizer and learning rate scheduler","metadata":{"_uuid":"586ae161-7e84-4096-b727-499bb5d7d1f2","_cell_guid":"76abdbe6-bf6b-4b36-90fa-696d133df918","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"EPOCHS = 20\nLEARNING_RATE = 2e-5\n\noptimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n\n# Total training steps: number of batches * epochs\ntotal_steps = len(train_loader) * EPOCHS\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=int(0.1 * total_steps),  # 10% of steps for warmup\n    num_training_steps=total_steps,\n)","metadata":{"_uuid":"15b7768f-14b9-4f92-aeaf-2cb02a6c11c2","_cell_guid":"47a4b808-145d-44aa-a188-91ca6475a2fe","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-20T09:15:28.080701Z","iopub.execute_input":"2025-11-20T09:15:28.080943Z","iopub.status.idle":"2025-11-20T09:15:28.095459Z","shell.execute_reply.started":"2025-11-20T09:15:28.080927Z","shell.execute_reply":"2025-11-20T09:15:28.094912Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## 9. Training loop","metadata":{"_uuid":"08e18f3e-c5ea-4c11-9691-ae549afb3387","_cell_guid":"13bc32e9-ea15-4f7f-8915-025d9f35c409","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def to_device(batch, device):\n    return {k: v.to(device) for k, v in batch.items()}","metadata":{"_uuid":"d5fcae9b-4f41-4831-b15f-7163f3c62783","_cell_guid":"7679cc65-8ec6-4e16-8989-794b12fe184b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-20T09:15:28.096127Z","iopub.execute_input":"2025-11-20T09:15:28.096394Z","iopub.status.idle":"2025-11-20T09:15:28.106949Z","shell.execute_reply.started":"2025-11-20T09:15:28.096368Z","shell.execute_reply":"2025-11-20T09:15:28.106385Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\ndef train_one_epoch(model, data_loader, optimizer, scheduler, device):\n    model.train()\n    total_loss = 0.0\n\n    for batch in tqdm(data_loader, desc=\"Training\", leave=False):\n        batch = to_device(batch, device)\n\n        optimizer.zero_grad()\n        outputs = model(**batch)\n        loss = outputs.loss\n\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        scheduler.step()\n\n        total_loss += loss.item()\n\n    return total_loss / len(data_loader)\n\n\n\ndef evaluate(model, data_loader, device):\n    model.eval()\n    preds = []\n    true_labels = []\n\n    with torch.no_grad():\n        for batch in tqdm(data_loader, desc=\"Evaluating\", leave=False):\n            batch = to_device(batch, device)\n\n            outputs = model(**batch)\n            logits = outputs.logits\n            batch_preds = torch.argmax(logits, dim=-1)\n\n            preds.extend(batch_preds.cpu().numpy())\n            true_labels.extend(batch[\"labels\"].cpu().numpy())\n\n    acc = accuracy_score(true_labels, preds)\n    f1 = f1_score(true_labels, preds, average=\"weighted\")\n    return acc, f1, preds, true_labels","metadata":{"_uuid":"8522e1e4-e173-486a-bfae-b209a340e22e","_cell_guid":"9441e2f2-92da-42a1-87b1-e6c712955fdc","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-20T09:15:28.107712Z","iopub.execute_input":"2025-11-20T09:15:28.108026Z","iopub.status.idle":"2025-11-20T09:15:28.118611Z","shell.execute_reply.started":"2025-11-20T09:15:28.108005Z","shell.execute_reply":"2025-11-20T09:15:28.117819Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## 10. Run the training over multiple epochs","metadata":{"_uuid":"3462a094-49c5-4d94-a265-e776ebecd796","_cell_guid":"3bccf5c0-ed6f-414f-9177-7d4500de8b63","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"best_f1 = 0.0\nbest_epoch = -1\npatience = 2              # how many epochs with no improvement to wait\nepochs_without_improve = 0\n\nfor epoch in range(EPOCHS):\n    print(f\"\\n===== Epoch {epoch + 1}/{EPOCHS} =====\")\n\n    train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, device)\n    print(f\"Average training loss: {train_loss:.4f}\")\n\n    acc, f1, preds, true_labels = evaluate(model, test_loader, device)\n    print(f\"Test accuracy: {acc:.4f}\")\n    print(f\"Test weighted F1: {f1:.4f}\")\n\n    if f1 > best_f1:\n        best_f1 = f1\n        best_epoch = epoch + 1\n        epochs_without_improve = 0\n        print(f\"New best model at epoch {best_epoch}, saving checkpoint...\")\n        output_dir = \"/kaggle/working/nepali-sentiment-model\"\n        os.makedirs(output_dir, exist_ok=True)\n        model.save_pretrained(output_dir)\n        tokenizer.save_pretrained(output_dir)\n    else:\n        epochs_without_improve += 1\n        print(f\"No improvement for {epochs_without_improve} epoch(s).\")\n\n    if epochs_without_improve >= patience:\n        print(f\"\\nEarly stopping triggered at epoch {epoch + 1}.\")\n        break\n\nprint(f\"\\nBest epoch was {best_epoch} with F1 = {best_f1:.4f}\")","metadata":{"_uuid":"3fde0ee4-4d6b-4db2-a05a-8bc9dca3b3dd","_cell_guid":"802fad50-0162-4e63-a2f8-8d7216992ec8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-20T09:15:28.119363Z","iopub.execute_input":"2025-11-20T09:15:28.119807Z","iopub.status.idle":"2025-11-20T09:35:00.901143Z","shell.execute_reply.started":"2025-11-20T09:15:28.119783Z","shell.execute_reply":"2025-11-20T09:35:00.900300Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"\n===== Epoch 1/20 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/450 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Average training loss: 0.8917\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Test accuracy: 0.7137\nTest weighted F1: 0.7034\nNew best model at epoch 1, saving checkpoint...\n\n===== Epoch 2/20 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/450 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Average training loss: 0.6622\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Test accuracy: 0.7650\nTest weighted F1: 0.7626\nNew best model at epoch 2, saving checkpoint...\n\n===== Epoch 3/20 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/450 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Average training loss: 0.5007\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Test accuracy: 0.7575\nTest weighted F1: 0.7560\nNo improvement for 1 epoch(s).\n\n===== Epoch 4/20 =====\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/450 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Average training loss: 0.3594\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Test accuracy: 0.7538\nTest weighted F1: 0.7529\nNo improvement for 2 epoch(s).\n\nEarly stopping triggered at epoch 4.\n\nBest epoch was 2 with F1 = 0.7626\n","output_type":"stream"}],"execution_count":15}]}